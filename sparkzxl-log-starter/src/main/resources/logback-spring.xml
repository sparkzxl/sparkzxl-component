<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE configuration>
<configuration>
    <include resource="org/springframework/boot/logging/logback/defaults.xml"/>

    <!--日志文件保存路径-->
    <springProperty name="springAppName" scope="context" source="spring.application.name" defaultValue="application"/>

    <springProperty name="logHome" scope="context" source="logging.file.path" defaultValue="../logs"/>

    <springProperty name="enableFile" scope="context" source="logging.file.enable" defaultValue="false"/>
    <springProperty name="enableConsole" scope="context" source="logging.enable-console" defaultValue="true"/>
    <springProperty name="enableJson" scope="context" source="logging.file.enable-json" defaultValue="false"/>
    <!-- kafka 配置 -->
    <springProperty name="enableKafka" scope="context" source="logging.kafka.enable" defaultValue="false"/>
    <springProperty name="kafka.servers" scope="context" source="logging.kafka.servers"/>
    <springProperty name="kafka.topic" scope="context" source="logging.kafka.topic"/>

    <!-- 控制台 日志格式化 -->
    <property name="CONSOLE_LOG_PATTERN"
              value="%clr(%d{${LOG_DATEFORMAT_PATTERN:-yyyy-MM-dd HH:mm:ss.SSS}}){faint} %blue(application): %green(${springAppName:-}) %highlight(${LOG_LEVEL_PATTERN:-%5p}) %clr(${PID:- }){magenta} %tid %clr(---){faint} %clr([%15.15t]){faint} %clr(%-40.40logger{39}){cyan} %clr(:){faint} %m%n${LOG_EXCEPTION_CONVERSION_WORD:-%wEx}"/>

    <!-- 控制台 Appender -->
    <appender name="console" class="ch.qos.logback.core.ConsoleAppender">
        <!-- 日志的格式化 -->
        <encoder class="ch.qos.logback.core.encoder.LayoutWrappingEncoder">
            <layout class="org.apache.skywalking.apm.toolkit.log.logback.v1.x.TraceIdPatternLogbackLayout">
                <Pattern>${CONSOLE_LOG_PATTERN}</Pattern>
            </layout>
        </encoder>
    </appender>

    <!--每天记录日志到文件appender-->
    <appender name="FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>${logHome}/${springAppName}.log</file>
        <append>true</append>
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
            <fileNamePattern>${logHome}/${springAppName}-%d{yyyy-MM-dd}.%i.gz</fileNamePattern>
            <maxHistory>7</maxHistory>
            <maxFileSize>50MB</maxFileSize>
        </rollingPolicy>
        <if condition='property("enableJson").contains("true")'>
            <then>
                <encoder charset="UTF-8" class="net.logstash.logback.encoder.LoggingEventCompositeJsonEncoder">
                    <providers class="net.logstash.logback.composite.loggingevent.LoggingEventJsonProviders">
                        <pattern>
                            <pattern>
                                {"date": "%d{yyyy-MM-dd HH:mm:ss.SSS}",
                                "level": "%level",
                                "service": "${springAppName:-}",
                                "traceId": "%tid",
                                "pid": "${PID:-}",
                                "thread": "%thread",
                                "class": "%logger{40}",
                                "message": "%message"}
                            </pattern>
                        </pattern>
                    </providers>
                </encoder>
            </then>
            <else>
                <!-- 日志的格式化 -->
                <encoder>
                    <pattern>${CONSOLE_LOG_PATTERN}</pattern>
                </encoder>
            </else>
        </if>
    </appender>
    <!-- 日志信息发送kafka -->
    <appender name="kafkaAppender" class="com.github.danielwegener.logback.kafka.KafkaAppender">
        <encoder>
            <pattern>
                {"date": "%d{yyyy-MM-dd HH:mm:ss.SSS}",
                "level": "%level",
                "service": "${springAppName:-}",
                "traceId": "%tid",
                "pid": "${PID:-}",
                "thread": "%thread",
                "class": "%logger{40}",
                "message": "%message"}
            </pattern>
        </encoder>
        <!-- kafka topic -->
        <topic>${kafka.topic}</topic>
        <!--<topic>test</topic>-->
        <keyingStrategy class="com.github.danielwegener.logback.kafka.keying.NoKeyKeyingStrategy"/>
        <deliveryStrategy class="com.github.danielwegener.logback.kafka.delivery.AsynchronousDeliveryStrategy"/>
        <!-- kafka 地址 -->
        <producerConfig>bootstrap.servers=${kafka.servers}</producerConfig>
    </appender>

    <!-- 异步传递策略，建议选择异步，不然连接kafka失败，会阻挡服务启动 -->
    <appender name="Async" class="ch.qos.logback.classic.AsyncAppender">
        <appender-ref ref="kafkaAppender"/>
    </appender>

    <root level="INFO">
        <if condition='property("enableFile").contains("true")'>
            <then>
                <appender-ref ref="FILE"/>
            </then>
        </if>
        <if condition='property("enableConsole").contains("true")'>
            <then>
                <appender-ref ref="console"/>
            </then>
        </if>
        <if condition='property("enableKafka").contains("true")'>
            <then>
                <appender-ref ref="Async"/>
            </then>
        </if>
    </root>
</configuration>
